Key Metrics:
- Accuracy: (the number of correct predictions / total number of predictions) = (pass/n)
    Useful with well balanced target classes [set contains even number of classes]
    
- Recall: Ability of model to find all relevant cases in a dataset 
    ** measures how many of the actual positive cases the model correctly identified:
    "Out of all the actual positive cases, how many did the model find?"

    (# true positives / (# true positives + # false negatives))

    - High recall is important when it's crucial to find all positive instances, even if it means some false positives.
    
- Precision: Ability of a model to find only the relevant data points
    ** measures how many of the positive predictions made were actually correct:
    "Out of all the cases the model predicted as positive, how many were actually positive?"

    (# true positives / (# true positives + # false positives))

    - High precision is important when it's crucial to avoid false positives, even if it means missing some actual positive cases.



- F1-Score: ML metric that combines both precision and recall into a single value (harmonic mean)
    ** punishes extreme values

    (F1 = 2 * (precision * recall)/(precision + recall))

__

Confusion matrix: A table that summarizes the performance of a classification model by showing how many instances of each class were correctly or incorrectly predicted.